## 传统的集成与问题

我们知道，越上层的软件做得大都是集成的工作。所以有一个名词叫做系统集成商。我在刚入行的时候，供职的几家公司都是这么称呼自己的。
	
而这些工作都做什么事呢，就是把人搞来搞系统集成。把多个系统集成在一起，搞个新系统。这种玩法是软件行业的主流，但是这种集成的方式是比较低效的，人们需要分析客户的需求，然后设计界面，开发功能，人工测试，排期上线，典型的软件开发。这个过程最大的问题在于，繁琐、冗长。基本上进入这个管道的需求，没有个把月是出不来的，虽然现在都号称敏捷了，最长也就是2周，但是吧，以大多数团队的实力，几个团队能两周就有信心上线呢？而且通常是需求多，人手少。有时候客户只要个简单的功能，前面至少排着两周的需求。有可能两周后，这个需求也不需要了。

所以大家开始搞所谓的low code，本质上就是想搞一些需求不要进入管道，快速响应。但是low code也一堆问题，比如面对客户的需求越来越复杂，low code也low不了，最后搞成了DSL甚至直接变成了通用的代码，对人员要求并不低。

这也没什么奇怪的，整个行业都是这么发展起来的，最早的时候人们说业务逻辑太烦了，然后发明了SQL，然后诞生了后端程序员和大量的后端需求。后来人们说前端太烦了，然后发明了HTML、CSS和Javascript，然后诞生了前端工程师和大量的前端需求，每一次试图推出low code的尝试最后只是诞生了新的工程师和新的需求场景。

因为做集成的时候不管是low code还是通用编程语言的代码，他们核心本质都是代码，是一种严丝合缝可以在机器上运行的机械化的规律。他们接受的输入是僵硬的，判断的逻辑是僵硬的，最后的输出也是僵硬的。

这种僵硬的机械化特质使得人必须去适应机器，于是新需求越多，适应的成本就越多，也就是要投入的开发成本就越高。

在大语言模型出现之前，世界一直都这么转，也没有什么别的办法。但是大语言模型的出现，给这个世界带来了一些新的思路。

那么有没有一种可能，给这种僵硬松松绑呢？

## 大语言模型带来的变化

我们通过两个例子来让大家看看大语言模型带来了哪些变化。

### 云化场景

对于上层的集成场景来说，其实算法要求并不是很多，大多数场景都是简单的if-else组合。而if后面跟的只能是表达式，而表达式本身都是僵硬的，他只能是一个比较确定的数值，缺乏灵活性。

比如我们做个对话机器人来处理『铜剑技校』的报名，假设它的执行效果是这个样子的：

```shell
欢迎来到铜剑技校！有什么我能帮您的吗？
请选择您需要的服务：
1. 报名课程
2. 其他
请输入选项编号：1
请选择您要报名的课程：
3. Python基础课
4. LLM编程课
5. 数据科学课
请输入选项编号：2
请回答以下问题：
您的姓名是什么？张三  
您的年龄是多少？18
您有多少年编程经验？
6. 0-1年
7. 1-3年
8. 3年以上
请输入选项编号：1
您报名这门课程的原因是什么？
9. 兴趣爱好
10. 工作需要
11. 学术研究
请输入选项编号：1

报名成功！以下是您的报名信息：
姓名：张三
年龄：18
编程经验：0-1年
报名原因：兴趣爱好
```

可以看到这是比较常见的交互流程，如果我用代码实现，可能是这个样子的（我故意把它的所有的分支都展开了）：

```python
def main():
    print("欢迎来到铜剑技校！有什么我能帮您的吗？")

    options = {
        1: "报名课程",
        2: "其他"
    }

    print("请选择您需要的服务：")
    for option in options:
        print(f"{option}. {options[option]}")

    while True:
        choice = input("请输入选项编号：")
        if choice.isdigit() and int(choice) in options:
            choice = int(choice)
            if choice == 1:  # 报名课程
                courses = {
                    1: "Python基础课",
                    2: "LLM编程课",
                    3: "数据科学课"
                }

                print("请选择您要报名的课程：")
                for course in courses:
                    print(f"{course}. {courses[course]}")

                while True:
                    course_choice = input("请输入选项编号：")
                    if course_choice.isdigit() and int(course_choice) in courses:
                        course_choice = int(course_choice)
                        if course_choice == 2:  # LLM编程课
                            print("请回答以下问题：")

                            name = input("您的姓名是什么？")

                            while True:
                                age = input("您的年龄是多少？")
                                if age.isdigit():
                                    break
                                else:
                                    print("无效的年龄，请重新输入。")

                            print("您有多少年编程经验？")
                            experience_options = {
                                1: "0-1年",
                                2: "1-3年",
                                3: "3年以上"
                            }
                            for option in experience_options:
                                print(f"{option}. {experience_options[option]}")
                            while True:
                                experience = input("请输入选项编号：")
                                if experience.isdigit() and int(experience) in experience_options:
                                    experience = int(experience)
                                    break
                                else:
                                    print("无效的选项，请重新输入。")

                            print("您报名这门课程的原因是什么？")
                            reason_options = {
                                1: "兴趣爱好",
                                2: "工作需要",
                                3: "学术研究"
                            }
                            for option in reason_options:
                                print(f"{option}. {reason_options[option]}")
                            while True:
                                reason = input("请输入选项编号：")
                                if reason.isdigit() and int(reason) in reason_options:
                                    reason = int(reason)
                                    break
                                else:
                                    print("无效的选项，请重新输入。")

                            print("\n报名成功！以下是您的报名信息：")
                            print(f"姓名：{name}")
                            print(f"年龄：{age}")
                            print(f"编程经验：{experience_options[experience]}")
                            print(f"报名原因：{reason_options[reason]}")

                            break
                        else:
                            print("该课程暂未开放报名。")
                            break
                    else:
                        print("无效的选项，请重新输入。")
                break
            else:
                print("感谢您的咨询！如果有其他问题，请随时向我们咨询。")
                break
        else:
            print("无效的选项，请重新输入。")

if __name__ == "__main__":
    main()
```
	
可以看到，这里面if后面跟的所有的表达式，都必须是严格的值。如果不是严格的值，也必须是一个正则表达式，或者其他表达式可以计算出来的，灵活度也是很差的。正如我们前面说的：僵硬。

那么大语言模型能给我们带来什么改变呢？我们先看看效果：

![技校客服-chat](https://jtong-pic.obs.cn-north-4.myhuaweicloud.com/chatgpt-coding-show/09-chatgpt-coding-show-s2/04-new-integration-pattern/S204-01-tech-academy-chat.png)

可以看到，我是比较随意的在跟我捏出来的客服对话，他可以很好的应对我的各种回答，并最终提交了表单。这过程中，用户的对话方式变得更灵活了。不是以前那样只能输入1、2、3以及格式化的文本的方式。从用户体验的角度，我们摆脱了僵化。

当然，你可能会说他最后不过是说了句话，哪里提交了表单？那我让他来给我看看他提交了什么表单数据。

![技校客服-表单提交](https://jtong-pic.obs.cn-north-4.myhuaweicloud.com/chatgpt-coding-show/09-chatgpt-coding-show-s2/04-new-integration-pattern/S204-02-tech-academy-enroll.png)


没错吧，是按照格式化文本提交了表单的。也就是说，我可以把前面随意的对话转化为一种符合特定规则的结构化文本。在真实的场景下，我只需要给一个根节点，然后以根节点为线索查找提取并parse这个根节点下的数据就好了。

那么我们再来看看实现，为了大家方便，我就直接贴文本了（用的时候把codeblock前面的“\”删掉）：

```markdown
下面是你的任务的信息，我会以markdown的形式编写：

\== 任务信息开始 ==/
## 上下文信息

### 名词解释

- Python指的是编程语言Python
- LLM是指大语言模型


## 任务描述

你是一个客服，你在为一个叫“铜剑技校”的组织进行服务，你需要通过对话的方式引导来访问这个组织的用户。你需要询问用户的意图，将他们的意图转化为这个组织能处理的各种表单，并提交给特定的服务。

### 可选的服务

最上层有两个选项可以提供给用户：

1. 报名课程
2. 其他

下面是两个选项的具体上下文细节，当用户选择了不同的选项，你需按照对应的上下文进行引导

#### 报名课程

在这个上下文里，我们支持三门课程：

1. Python基础课
2. LLM编程课
3. 数据科学课

而报名的表单格式为：

\```xml
<姓名>张三</姓名>
<年龄>18</年龄>
<编程经验>0-1年</编程经验>
<报名原因>兴趣爱好</报名原因>
\```

报名原因要引导用户在下面三个中选择：
1. 兴趣爱好
2. 工作需要
3. 学术研究
如果你根据用户的输入判断是上面之一，你也可以跟客户确认一下，而不是生硬的让他选这三个之一。

编程经验要根据用户输入归为下面的分类：
1. 0-1年
2. 1-3年
3. 3年以上

这个格式是最终你提交的格式，你需要引导用户提供报名信息，但不要让用户通过这种格式给你提供信息

#### 其他

- 如果用户选择了“其他”，你就直接与之对话，对话内容可以随意，但不能发表损害“铜剑技校”的权益的言论。
- 如果用户提到了别的服务，可以引导到别的服务上去。

### 要求

- 在最后提交之前，要把表单格式转化为用户能理解的形式让他确认。

### 互动方式
我们会以下面的格式对话：

我: <我说的话>
“人工”客服: <你的回复>

我每次都会把之前的对话记录发给你。


\== 任务信息结束 ==/

开始互动吧，这是之前的对话记录：

我: 你好。
```

可以看到，这个里面没有任何的写死的用户输入的格式，有的只是一些背景上下文和应对的对话原则，以及输出格式。所以他最后可以输出结构化文本的内容。

而如果我们按照这里面说的，去聊点其他的呢：

![技校客服-其他chat](https://jtong-pic.obs.cn-north-4.myhuaweicloud.com/chatgpt-coding-show/09-chatgpt-coding-show-s2/04-new-integration-pattern/S204-03-tech-academy-other-chat.png)

可以看到，我的小客服忠不可言，不肯说我们的坏话。而且，当我放弃挖黑料之后，他又可以导向我的课程，帮我处理报名了。更多用法大家可以自己试验，这里就不演示了。

有了这个之后，我们就可以很轻易的捏一个服务人员出来，他可以轻松地处理与人的对话并把用户的需求翻译成可以调用后端服务的API的数据。

这会带来什么好处呢？

要知道，它能翻译一个就可以翻译多个，于是他就提供了一种新的集成方式。这样的话，我们就可以用大语言模型在最前面对接用户，让他把用户需求转化为传统后端服务可以消费的数据结构。并且根据情况调用不同的API，最大限度的利用现有的后端服务。

我们知道，很多企业内服务，他们功能虽然有，但是UI做的那是真难用。那么对于大多数的企业来说，我们就可以以很低的成本制造一个前端，它开发成本非常低且易用。

如果LLM产生“幻觉”，进行编造怎么办？那也好办，编造会有两种可能性：
1. 生成的数据内容有错误。这就是我为什么在流程里加入了最后的确认步骤。实际上你想想，如果对边真的是个人，他会犯错，你是不是也会希望他提交前跟你确认一下。 
2. 生成的数据格式不合法。如果数据结构不合法，没关系，因为调用的后端服务会报错的嘛，就再生成一遍就好了。什么时候合法了，什么时候结束。在用户视角，这只是一个等待中的感觉。

其实真实使用的时候，还可以有其他做法。比如确认的可能直接就是个界面，谁说大语言模型的UI就只能显示文本？嵌入一个卡片有什么不行？这XML可以直接渲染成UI嘛。比如这UI是个表单，上面有个按钮，然后人一点提交就完了。格式错了，连表单都生成不出来，不就更可靠了？

所以这个方式从逻辑上讲是最可信的，而同时这种集成的实现方式带来的体验是颠覆性的，有了这样一个方式，我们可以以更快的速度增加企业的数字化能力，从而不用背着那么重的UI遗产进行演进迭代。

想想都是一件美好的事情。

### 物联网场景

即便是一些物联网的场景，我们也可以让这种模式带来一些改变。比如在IoT领域，我们也可以通过手机来实现一些颠覆性的体验。作为一名咨询师，我经常出差，有些旅馆里似乎是为了提供更好的体验，会提供一个小爱之类的智能音箱。你可以指挥它给你开关灯、拉窗帘。有的在厕所里还给你安装了智能马桶。但是不管哪个，都没给我带来什么好体验。

比如智能音箱你让他拉开窗帘的时候，他把窗帘窗纱都给你拉开了。你让他关灯，你光理解哪个灯叫哪个名字就累死你，或者你就只能干脆全开全关。而智能马桶就更过分了，控制面板上有16个按钮，而且不支持语音控制。这些智能设备，在我的视角，基本上就相当于智障设备。

那么如果我们在智能设备上接入一个LLM，岂不是就变身智能设备了？

我的朋友陶文研究了一种很简单的prompt，可以在这些小模型上依然工作，加入我们有一个API，接受action表示要干什么，接受一个target表示操作谁，然后我们可以用几个例子让他进行in context learning，根据我们输入的文本来将我生成对应的action和target:

```text
please fill in the blanks
{ input: 'please turn off  the light of living room', action: 'bulb-off', target: 'living-room' }
{ input: 'switch on  the lamp at kitchen', action: 'bulb-on', target: 'kitchen' }
{ input: 'turn on  the lamp at kitchen', action: 'bulb-on', target: 'kitchen' }
{ input: 'please light up the lamp on my desktop', ____ } 
```

这个prompt就是通过例子，让它仿照着续写出入：如果是最后一个输入，空上填什么？因为用到了思维链的技术，所以会根据上面的来稳定输出，其结果是：

![iot en](https://jtong-pic.obs.cn-north-4.myhuaweicloud.com/chatgpt-coding-show/09-chatgpt-coding-show-s2/04-new-integration-pattern/S204-04-iot-en.png)

可以看到，我们的意图意图翻译成了对应的action和target。

我们的意图是中文也可以：
-
  ```text
  please fill in the blanks
  { input: 'please turn off  the light of living room', action: 'bulb-off', target: 'living-room' }
  { input: 'switch on  the lamp at kitchen', action: 'bulb-on', target: 'kitchen' }
  { input: 'turn on  the lamp at kitchen', action: 'bulb-on', target: 'kitchen' }
  { input: '请打开我桌子上的台灯', ____ } 
  ```
其结果是：

![iot zh](https://jtong-pic.obs.cn-north-4.myhuaweicloud.com/chatgpt-coding-show/09-chatgpt-coding-show-s2/04-new-integration-pattern/S204-04-iot-en.png)


必要的话，我们可以把这里面的常量也提前放到我们的prompt里。告诉它选哪个，这里我们就不演示了。

当然，智能设备上有个LLM，还能接语音，先不说耗能吧，这事听着就很吓人。你把我的声音都录进去，你想干什么？

那么换个思路，我们在手机上装一个大语言模型，在进入房间的时候，把这些设备的API都通过二维码都给扫到手机里，或者NFC读进手机也行。然后我就可以用手机操作房间里的各种设备了，只要你的智能设备开放API且我的手机里有一个LLM。而现在已经有一些简单的小模型可以在手机上跑起来了，比如MLC LLM。

随着手机设备的进一步升级，周边生态的进一步成熟，我觉得这个未来也不遥远。

## 总结

大语言模型(LLM)的出现带来了软件交互方式的革新，显著提升了用户体验。LLM的灵活性允许其理解多种用户输入，避免了传统代码输入的僵化，同时为用户体验的提升创造了重要价值。在传统的交互方式中，用户往往被限定在固定的选项中选择，而LLM允许用户使用自然语言来表述自己的需求。

而同时，虽然LLM存在“幻觉”等问题，它根据用户的描述选择特定的服务，还是很擅长的。而且LLM非常擅长进行翻译等工作，所以需求转化为后端API所需的特定格式的输入并不是什么难事。以此能力为核心我们可以得到一种新的集成模式。

我们以报名系统为例，演示了这个过程和实现方式。LLM改变了传统的报名流程。用户不再需要选择复杂的选项，而是可以使用自然语言直接表述报名需求，使得整个过程更加舒适自然。最后，用户可以通过确认界面保证信息的准确性，这使得整个体验更为人性化的同时，还避免了LLM的“幻觉”问题。

当然，在现实应用中，需求千变万化，LLM的响应速度并不一定能满足所有的需求。然而，相比于传统的编码方式，使用LLM进行集成可以更快地推出新的功能和服务。在云化场景下可以更快速的提升企业的数字化能力，成本很低的同时，用户体验还很好。

这种用法未必只能用在云化场景，在IoT的场景下，我们可以把我们的手机变成一个超级智能的大管家，把我们的智能家居变成真正的智能家居，而不是现在的“智障”家居。
这种新的集成方式带来的新的用户体验，是我认为近期LLM对现实世界的软件产生明显影响的最可能的一种方式。