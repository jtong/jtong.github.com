***随着Claude推出了100K context window，开源社区也在日新月异的追赶，ChatGPT可能渐渐地要从唯一转变为之一了，所以我们就不在文章里强调ChatGPT了，因为我们的手法对于大语言模型（LLM）是通用的，只是大语言模型什么时候普遍具备ChatGPT现如今的能力的问题***

这次我们我们继续往前，我们这次走的靠前一点，因为我们上一节已经讲了，怎么做任务分解，那么很自然的就会想到需求分析。很自然的，我们也会想到如果他再能够帮我们分析需求，是不是就可以提出需求，直到最后生成代码全部自动完成了呢。简单的说，没有这么简单，这里涉及到大语言模型，包括ChatGPT很多天生的缺陷。

## LLM的边界与普适的交互模式

我们从编程开始看起来给大家演示了很多眼花缭乱的场景，这些场景看起来好像很难很复杂，但其实编程对大语言模型来说真的是最友好的领域了。还记得大语言模型天然的缺陷吗？那就是它是一个概率模型，所以它的生成既不稳定也不一定正确。也就是说同一个问题他每次都回答。都可以是不一样的。不但是不一样的，也不能保证每一次都是对的。这就使得在大语言模型这个AIGC的时代，内容的生成变得不再是核心竞争力。验证变成了核心的竞争力。而在编程领域，验证恰恰是最容易自动化的。我们甚至还有一整套的基础设施。来帮助我们多目的多角度的对它生成的代码进行验证。

那前面为什么讲任务分解的时候没说呢？任务分解呢，其实就已经没有那么容易了。因为任务分解他生成的任务是否正确这件事情，是需要人来验证的，或者走到下一步，生成完代码再来验证，这已经就不如代码了。不过还好，因为任务分解，毕竟分解的是编程任务，从生成任务到获得代码是很顺畅的，按理说中间是不需要其他的人进行交接的，所以任务分解也可以约等于是可以被自动化验证的。而任务模板还有架构之类的东西。我们可以用典型需求来测试他一下，一定程度上测试过之后，我们就可以认为这一段话就类似于一个代码，它上一次可以执行，下次应该也可以执行。如果下一次不能执行了，一定是用的人有问题。不过即便如此，大语言模型本身的逻辑性差的话，依然会造成大量的浪费。这点上就是为什么GPT4是如此特殊的原因。它是目前唯一一个可以相对严丝合缝进行推理的模型。

那么比任务分解再往前一步的需求就更要命了，需求离代码就更加遥远，需求的错误恐怕只能靠人来判断。从需求到代码实现之间只怕是没有那么多的时间和算力可供你去做自动化的判断。所以我们可以看出来大语言模型的另外一个边界。因为他的不稳定和幻觉（也就是大多数人看到的内容编造）。所有大语言模型生成的内容。都必须要经过反馈、调整、确认，最后才能使用。所以如果反馈调整确认的成本，超过了一个人直接判断的成本，那么我们就不能认为大语言模型具有给我们带来成倍数的效率提升的潜力了。那么在除了编码外的绝大多数领域，可能它的一个交互模式都是如下图所示的：

![llm-interactive-model](https://jtong-pic.obs.cn-north-4.myhuaweicloud.com/chatgpt-coding-show/09-chatgpt-coding-show-s2/02-acceptance-criteria/S202-01-llm-interactive-model.png)


那么按照这个模式，在需求分析领域最适合做什么呢？其实是验收条件的分析。

## 如何用LLM分析验收条件

我们用一个例子来展示一下，假设我们要做一个在线学习平台，是用于企业内员工培训的学习项目的，比如说毕业生的入职培训，社招人员的入职培训，特定人员的培养计划，以及企业里各种不同职级的要求而产生的一系列的学习需求等等。那么这样一个系统呢，我们假设有三个角色：学员、教研和教练。学员自然是学习者，而教研则是学习项目的设计者，而教练呢，则是学习项目的实施辅助人员，帮助学员完成学习项目提升学习效果。

那么我们的演示就是让LLM帮助我们针对这样一个平台里面的需求编写验收条件。这里我采用敏捷的交付件标准，把需求拆解为用户故事，然后让大语言模型基于用户故事进行验收条件的分析。

我们先给他一个典型的用户故事：作为教练，我希望可以用markdown描写任务卡上的学习任务，这样我就可以用我们擅长的文本方式描写复杂的富文本内容。

![ac-generate-template](https://jtong-pic.obs.cn-north-4.myhuaweicloud.com/chatgpt-coding-show/09-chatgpt-coding-show-s2/02-acceptance-criteria/S202-02-ac-generate-template.png)

可以看到，这么简单一个故事，我其实给了他很多前置信息，我介绍了典型的用户角色，给他讲了架构上下文，然后是介绍了什么是用户故事，什么是验收条件，并界定了格式。这些东西是非常重要的，没有这些东西，后面大语言模型是没法思考的。很多人都会期望大语言模型就像一个许愿机，我只用许愿就可以了。但是它其实更像一个人，你要想让一个人能干活，这个人需要先知道哪些信息，你也得都给他，通常是以文档的形式。所以从另一个角度来讲，在今天，我们的文档写得好不好，有了一个真正客观的验收条件：大语言模型能不能消费它之后，进行特定的任务。若不能，你的文档写的就有点差。

从另一个角度来讲，这就是为什么大语言模型在需求分析领域最适合做验收条件的分析。因为即便大语言模型有推理能力，他也只是推理，不能凭空产生知识，那么你给他的前置的上下文输入决定了它推理的范畴。

接下来，我们来看看ChatGPT对这段prompt的反应：

![ac-generate-response](https://jtong-pic.obs.cn-north-4.myhuaweicloud.com/chatgpt-coding-show/09-chatgpt-coding-show-s2/02-acceptance-criteria/S202-03-ac-generate-response.png)

可以看到他问了我一些问题，通常你哪怕前面写了，大语言模型也会问一些问题。我回答了他，然后他就开始给我分析验收条件了。所以我们可以看到，我在前面的prompt里面专门强调了，如果他判断有不清楚的，要向我提问。可以看出来，我没有讲清楚是针对架构里哪个系统组件描写的验收条件，我补充了是从界面角度写，所以它就给我往后写了。

这是个很有趣的事情，这一点上，你仔细想想，大语言模型扮演了什么？它其实扮演了一个下游反馈者，那么对于一个需求分析人员可能有哪些下游反馈者呢？通常是两个：

- 一个下游反馈者可能是你手底下给你打下手的“小工”，比如需求分析人员我们也叫BA（Business Analyzer，业务分析师），那么有时候有一个角色是所谓的大BA，它复杂宏观一点的大的故事的编写和大的功能点的设计，而另一个角色是所谓的小BA，他负责把大BA的工作分解和细化并补充验收条件。那么大语言模型就扮演了这个小BA。
- 那么另一个下游反馈者呢，则是下游的开发人员，开发人员会从实现的角度更多的思考，从而质疑你这个故事卡逻辑上有没有问题，能不能实现。这里要想做到这个效果呢，可能需要关联一个代码库，作更复杂的基于大语言模型的功能才能实现，这个我们后面其他章节再讲，这里就不深入讲解了，大家知道这种可能性就好。

所以说从这个角度来讲，我们用大语言模型来帮助我们分析验收条件，可以最大限度的提前获得一些下游的反馈和疑问，这对于需求分析人员是很有帮助的，对于整个流程来说也可以减少很多浪费。

那么接下来，我们再看看大语言模型分析验收条件本身的能力如何，这个story我选择了一个刚刚好需要多个验收条件的，于是可以看到他考虑了各种情况下的验收条件。但是在当年我们做这个平台的时候，各种Markdown的库支持还不是那么的全面代码的展示、各种图示的展示以及视频通过嵌入HTML展示都未必能支持的那么好，所以从验收的角度，我们要专门验收这几个点。甚至有难度的话，我们可能会把验收条件单独拆出去做张卡。于是我们可以继续要求：

![ac-generate-response-feedback](https://jtong-pic.obs.cn-north-4.myhuaweicloud.com/chatgpt-coding-show/09-chatgpt-coding-show-s2/02-acceptance-criteria/S202-03-1-ac-generate-response-feedback.png)

那么可以看到，大语言模型是可以帮我们分析验收条件的，但要注意的是，我们更多的只能期望它在我们的反馈下工作。在我们的反馈下，有时他可以帮我们做一些体力活，这种体力活，本来也不是我们爱干的，我们可以交给大语言模型去干；有时也能帮我们想一些分支情况，但是他并不一定能发现所有的分支情况，可以看到有的时候是它想到了，比如这里面的安全性，我之前就没想到。有的时候是我想到了，比如几种不同的markdown的关键特性。所以这个场景下，我们总是需要与它反馈协作按照上面的模式进行互动，自己可不能停止思考。

最后我们来聊聊一些特殊情况，比如有些同学的场景可能是不涉及前端的，会怀疑他也能分析么？我们可以试试：

![ac-generate-backend](https://jtong-pic.obs.cn-north-4.myhuaweicloud.com/chatgpt-coding-show/09-chatgpt-coding-show-s2/02-acceptance-criteria/S202-04-ac-generate-backend.png)

可以看到，红框部分标出了他的关注点，而结果虽然比较的粗略，但是确实是只针对后端部分编写了验收条件。从这个Prompt的模版上可以看出，只要我们限定了上下文，让大语言模型在这个限定的上下文下进行细化和推导，还是很擅长的。

## 总结

下面是ChatGPT给我写的总结（是的，你看，体力活总是可以让他去干的）：

===AI生成的内容===

当涉及到大语言模型在需求分析领域的应用时，以下是本文的主要要点总结：

1. 大语言模型的边界和交互模式：
   - 大语言模型存在不稳定性和生成结果的幻觉。
   - 在编程领域，验证可以相对容易地自动化，但在需求分析领域，验证变得更加困难，通常需要人工判断。

2. 使用大语言模型分析验收条件：
   - 大语言模型在需求分析中扮演下游反馈者的角色。
   - 需求分析人员可以将用户故事作为输入，让大语言模型生成相关的验收条件。
   - 大语言模型在分析验收条件时需要与需求分析人员进行反馈和互动，共同思考和补充细节。

3. 大语言模型分析验收条件的能力：
   - 大语言模型可以帮助进行一些体力活和分析分支情况。
   - 需要与大语言模型进行协作和思考，它并不是完全替代需求分析人员的角色。

4. 特殊情况：
   - 大语言模型可以限定上下文，以在特定领域进行细化和推导，即使不涉及前端部分也具备一定的分析能力。

综上所述，大语言模型在需求分析领域具有潜力，可以辅助需求分析人员自动化验证和生成验收条件。然而，需求分析仍然需要人工思考和判断，并与大语言模型进行反馈和互动，以确保最终结果的准确性和可行性。

===AI生成的内容结束===

机器替我完成了体力活，作为人类，我觉得我可以站在机器的肩膀上再往前思考一下，所以我又继续思考了一下。

## 再往前一步就是边界

那么看到了我们可以用大语言模型做验收条件的分析，是不是可以更往前一点分析出用户故事呢？也不是不行，毕竟我们有一个工具叫用户故事地图，可以用于进行这个工作。所谓用户故事地图，是用户经历的一个比较长的历程。想象一个画面，这个历程是一个带有有向剪头的射线，最左边是起点，最右边是箭头。所以这条历程表达的是一根时间线。这根时间线之外，左侧是用户角色，标明了这个历程是谁的历程，右侧是目标，标明了这个历程的终点是想达成什么目标:

![user-story-map.](https://jtong-pic.obs.cn-north-4.myhuaweicloud.com/chatgpt-coding-show/09-chatgpt-coding-show-s2/02-acceptance-criteria/S202-05-user-story-map.png)

当然这些历程还可以再串起来形成更长的地图:

![multi-role-user-story-map](https://jtong-pic.obs.cn-north-4.myhuaweicloud.com/chatgpt-coding-show/09-chatgpt-coding-show-s2/02-acceptance-criteria/S202-06-multi-role-user-story-map.png)

这个地图，我们只要转化成文本描述，大语言模型也可以帮助我们生成，但更多的只是帮助我们细化。**然后再往前一步，你会感觉几乎撞上了一堵墙。那就是：到底有哪些角色，他们都有哪些目标**。

我们来举个例子，让大家更好的去理解一下这中间能做的和不能做的事情。比如说我现在还是要做一个在线学习系统。这在线学习系统呢可以有两种：一种是面向个人用户的，一种是面向企业用户的。面向个人用户付钱的人是个人。他自己去解决他有没有投入时间在学习这个问题。而面向企业用户付钱的是企业。企业通常对于员工学习是有一些所谓的学习项目的，企业会设计一堆促学的机制，前面已经给讲过了。

这两者基本上就是两种系统。前者可能更关注于内容的呈现。而后者则更关注于系统内企业内各个角色围绕着被培养人员的一系列的互动。比如毕业生培训的话，可能会关注学员的做作业的过程当中。学员的完成效率、平均的成绩的变化、关注于学员的考试的成绩的变化，还有教练对学员的反馈，教练自身的绩效表现等。**那么假设我们做的是一个面向企业内的各种学习计划的平台。当我们确定这一步的时候，我们是不是可以开始需求分析了呢？其实当我们确定这一步的时候，需求分析已经开始好久了**。

当我说我要做企业内一个学习系统的时候，为了讲清楚到底什么是企业内的一个学习系统，那么学员、教练、学习计划、作业、成绩、反馈、绩效这些概念自然就出现了。有些概念则隐含其中，比如成绩、反馈、绩效到底是怎么来的？作业是怎么出的？谁出的？随之而来的我们可能会定义出：教研，训练营、课程、任务卡、练习、考试等等新概念。

**最核心，最关键的点就是在最初的这些简单概念的引入上**，随着引入的概念越来越多，这个问题的方向性就会越来越明确。然后逐渐过渡到系统做什么，也就是所谓system does的问题上。后者一定程度上大语言模型就可以比较套路化的帮助我们，而前者则比较难。《道德经》讲无名，天地之始，有名，万物之母。当我们开始思考这个案例的时候，我们想象一张白纸，这里面好多概念是不存在的，然后渐渐地随着一句句描述这个系统是什么的话被说出，这些概念一个个出现在白纸上。一个事物，当他具有名字那一刻之前，发生了什么呢？其实我们是说不太清楚的。这个过程本身存在相当大的隐性知识，而**大语言模型的边界就在这个隐性知识中**。

我之前听了一个报告，说上一波AI主要面向的是隐性知识，也就是人类语言无法描述的知识。比如如何骑自行车保持平衡，这就没法用人类语言描述，描述了你也学不会。而这一波的AI则主要面向显性知识，也就是人类语言可以描述的知识。虽然怎么引导需求分析这个事情，我个人认为是可以说清楚的，但是投入产出比可能极为的不划算。需求分析这件事情，最主要的脑力工作是定义系统是什么。一旦定义完了系统是什么，那么剩下的是定义系统做什么。而关于系统做什么，大都是是体力活儿，比如细化功能点啊，功能点的细节分析啊，功能彼此之间有没有冲突啊，为了达成这个目标，都有哪些方案啊等等。目前来讲做系统做什么这件事情大语言模型可以通过提示词模板的方式，带来极大的效率提升。而系统是什么这件事情，大语言模型也能帮我们做一些事情。但是这个领域就非常受制于操作人自身的能力，也就是说到现在为止，我们终于又要面临人的能力瓶颈了，这就又回到了我们传统的能力建设的挑战：假如一个人能力不行，我们要教会他，让他能用大语言模型做好定义system is这件事情。而这跟我们以前想要教一个普通人成为习惯良好的程序员一样难。

总结一下，大语言模型在system does，也就是系统做什么的问题上可以给我们很多帮助，但是在system is，也就是系统是什么的问题上能给的帮助有限，其表现十分受限于人自身的能力。而这个定义系统是什么的场景，不但需求分析领域有这个场景，建模、架构领域都有这个场景。所以不但需求分析人员面临这个问题，架构师也会面临同样的问题。不过也不要因此失望，这说明了大量关于system does的体力活上，我们还是可以节省相当多的成本的，而system is本来也是人需要回答的问题。
